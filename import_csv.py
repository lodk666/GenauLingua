"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ —Å–ª–æ–≤ –∏–∑ CSV —Ñ–∞–π–ª–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
"""
import asyncio
import csv
from pathlib import Path
from typing import Optional, List
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy import select
from app.database.models import Base, Word, PartOfSpeech, CEFRLevel


# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
DATABASE_URL = "postgresql+asyncpg://genau_user:genau_password@localhost:5432/genaulingua_db"


def parse_categories(categories_str: Optional[str]) -> List[str]:
    """–ü–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ —Å—Ç—Ä–æ–∫–∏"""
    if not categories_str or categories_str.strip() == "":
        return []
    return [cat.strip() for cat in categories_str.split("|") if cat.strip()]


def parse_pos(pos_str: str) -> PartOfSpeech:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–∞—Å—Ç–∏ —Ä–µ—á–∏ –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤ enum"""
    pos_mapping = {
        "noun": PartOfSpeech.NOUN,
        "verb": PartOfSpeech.VERB,
        "adjective": PartOfSpeech.ADJECTIVE,
        "adverb": PartOfSpeech.ADVERB,
        "phrase": PartOfSpeech.PHRASE,
        "pronoun": PartOfSpeech.PRONOUN,
        "preposition": PartOfSpeech.PREPOSITION,
        "conjunction": PartOfSpeech.CONJUNCTION,
    }
    return pos_mapping.get(pos_str.lower(), PartOfSpeech.OTHER)


def clean_string(value: Optional[str]) -> Optional[str]:
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç—Ä–æ–∫–∏ –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
    if not value or value.strip() == "":
        return None
    return value.strip()


async def import_words_from_csv(
    csv_path: str,
    level: CEFRLevel = CEFRLevel.A1,
    clear_existing: bool = False
):
    """
    –ò–º–ø–æ—Ä—Ç —Å–ª–æ–≤ –∏–∑ CSV —Ñ–∞–π–ª–∞
    
    Args:
        csv_path: –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É
        level: –£—Ä–æ–≤–µ–Ω—å CEFR –¥–ª—è –≤—Å–µ—Ö —Å–ª–æ–≤
        clear_existing: –£–¥–∞–ª–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–ª–æ–≤–∞ –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º
    """
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
    engine = create_async_engine(DATABASE_URL, echo=True)
    async_session = async_sessionmaker(
        engine, 
        class_=AsyncSession, 
        expire_on_commit=False
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
    
    async with async_session() as session:
        # –û—á–∏—Å—Ç–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–ª–æ–≤ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if clear_existing:
            print("üóëÔ∏è –£–¥–∞–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–ª–æ–≤...")
            await session.execute(select(Word))
            await session.commit()
            print("‚úÖ –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–ª–æ–≤–∞ —É–¥–∞–ª–µ–Ω—ã")
        
        # –ß—Ç–µ–Ω–∏–µ CSV
        csv_file = Path(csv_path)
        if not csv_file.exists():
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")
            return
        
        print(f"üìñ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {csv_path}")
        
        with open(csv_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            
            words_added = 0
            words_skipped = 0
            
            for row_num, row in enumerate(reader, start=2):  # start=2 —Ç.–∫. –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –∑–∞–≥–æ–ª–æ–≤–∫–∏
                try:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –Ω–µ–º–µ—Ü–∫–æ–≥–æ —Å–ª–æ–≤–∞
                    word_de = clean_string(row.get('word_de'))
                    if not word_de:
                        words_skipped += 1
                        print(f"‚ö†Ô∏è –°—Ç—Ä–æ–∫–∞ {row_num}: –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–ø—É—Å—Ç–æ–µ –Ω–µ–º–µ—Ü–∫–æ–µ —Å–ª–æ–≤–æ)")
                        continue
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø–µ—Ä–µ–≤–æ–¥
                    translation_ru = clean_string(row.get('translation_ru'))
                    translation_uk = clean_string(row.get('translation_uk'))
                    
                    if not translation_ru and not translation_uk:
                        words_skipped += 1
                        print(f"‚ö†Ô∏è –°—Ç—Ä–æ–∫–∞ {row_num}: –ø—Ä–æ–ø—É—â–µ–Ω–∞ '{word_de}' (–Ω–µ—Ç –ø–µ—Ä–µ–≤–æ–¥–æ–≤)")
                        continue
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ —Å–ª–æ–≤–∞
                    word = Word(
                        word_de=word_de,
                        article=clean_string(row.get('article')),
                        pos=parse_pos(clean_string(row.get('pos', 'other')) or 'other'),
                        level=level,
                        translation_ru=translation_ru,
                        translation_uk=translation_uk,
                        example_de=clean_string(row.get('example_de')),
                        example_ru=clean_string(row.get('example_ru')),
                        example_uk=clean_string(row.get('example_uk')),
                        categories=parse_categories(row.get('categories'))
                    )
                    
                    session.add(word)
                    words_added += 1
                    
                    # –ö–æ–º–º–∏—Ç–∏–º –∫–∞–∂–¥—ã–µ 100 —Å–ª–æ–≤
                    if words_added % 100 == 0:
                        await session.commit()
                        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {words_added} —Å–ª–æ–≤...")
                
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {row_num}: {e}")
                    print(f"   –î–∞–Ω–Ω—ã–µ: {row}")
                    words_skipped += 1
                    continue
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–º–º–∏—Ç
            await session.commit()
            
            print("\n" + "="*50)
            print(f"‚úÖ –ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω!")
            print(f"üìä –î–æ–±–∞–≤–ª–µ–Ω–æ —Å–ª–æ–≤: {words_added}")
            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Å—Ç—Ä–æ–∫: {words_skipped}")
            print("="*50)
    
    await engine.dispose()


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import sys
    
    # –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É
    csv_path = "Word base/A1/A1 cvc/A1_missing_90_words.csv"
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    level_str = sys.argv[1] if len(sys.argv) > 1 else "A1"
    clear_existing = "--clear" in sys.argv
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —É—Ä–æ–≤–Ω—è
    level_mapping = {
        "A1": CEFRLevel.A1,
        "A2": CEFRLevel.A2,
        "B1": CEFRLevel.B1,
        "B2": CEFRLevel.B2,
        "C1": CEFRLevel.C1,
        "C2": CEFRLevel.C2,
    }
    level = level_mapping.get(level_str.upper(), CEFRLevel.A1)
    
    print(f"üöÄ –ó–∞–ø—É—Å–∫ –∏–º–ø–æ—Ä—Ç–∞...")
    print(f"üìÅ –§–∞–π–ª: {csv_path}")
    print(f"üìö –£—Ä–æ–≤–µ–Ω—å: {level.value}")
    print(f"üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –ë–î: {'–î–∞' if clear_existing else '–ù–µ—Ç'}")
    print()
    
    await import_words_from_csv(
        csv_path=csv_path,
        level=level,
        clear_existing=clear_existing
    )


if __name__ == "__main__":
    asyncio.run(main())
